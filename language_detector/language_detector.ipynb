{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "525ca28f-ef0f-40be-970a-50cc3ff46e88",
    "_uuid": "e0e7e10ba0f5f5eae80910f707e1ea7ac37dcbf5"
   },
   "source": [
    "## Libraries <a class=\"anchor\" id=\"zero-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "7ee6031d-8cd8-4032-bbe6-610d7a766739",
    "_uuid": "0db70516824bb855c9d967bcff89640c981107b2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c5ab9cf5-b38a-43a7-8f38-b09551b88ac1",
    "_uuid": "c649488e0e8c84615d8865763cfb10e66a72e3f3"
   },
   "source": [
    "## Data set preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "af749267-ad41-4083-a886-2925b20b775a",
    "_uuid": "641b81d04ee698f9bb3c7ff062f97026bdc57a33"
   },
   "source": [
    "Read the data set <a class=\"anchor\" id=\"read_data\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng = pd.read_csv('Eng.csv')\n",
    "df_tr = pd.read_csv('Turkish.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>21665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>prow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Words\n",
       "count   21665\n",
       "unique  21665\n",
       "top      prow\n",
       "freq        1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eng.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21666 entries, 0 to 21665\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Words   21665 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 169.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_eng.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kelimeler</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ugunma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Kelimeler\n",
       "count       2235\n",
       "unique      2235\n",
       "top       ugunma\n",
       "freq           1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tr.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2235 entries, 0 to 2234\n",
      "Data columns (total 1 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Kelimeler  2235 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 17.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_tr.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Turkish characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([], dtype='int64')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_tr_chr = df_tr['Kelimeler'].str.contains('ç|ğ|ı|ö|ş|ü|', regex=False)\n",
    "check_tr_chr[check_tr_chr].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Creation\n",
    "### Since the data is provided as single words, context or grammar does not exist\n",
    "### The position of letters and their sequence can be useful features\n",
    "### First thing to do to is split the words into letters and record their postions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f</td>\n",
       "      <td>r</td>\n",
       "      <td>a</td>\n",
       "      <td>k</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f</td>\n",
       "      <td>a</td>\n",
       "      <td>s</td>\n",
       "      <td>i</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f</td>\n",
       "      <td>e</td>\n",
       "      <td>c</td>\n",
       "      <td>i</td>\n",
       "      <td>r</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f</td>\n",
       "      <td>o</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f</td>\n",
       "      <td>l</td>\n",
       "      <td>u</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2230</th>\n",
       "      <td>k</td>\n",
       "      <td>a</td>\n",
       "      <td>l</td>\n",
       "      <td>i</td>\n",
       "      <td>c</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2231</th>\n",
       "      <td>k</td>\n",
       "      <td>o</td>\n",
       "      <td>r</td>\n",
       "      <td>v</td>\n",
       "      <td>e</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2232</th>\n",
       "      <td>k</td>\n",
       "      <td>a</td>\n",
       "      <td>s</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2233</th>\n",
       "      <td>k</td>\n",
       "      <td>o</td>\n",
       "      <td>c</td>\n",
       "      <td>m</td>\n",
       "      <td>a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2234</th>\n",
       "      <td>k</td>\n",
       "      <td>u</td>\n",
       "      <td>m</td>\n",
       "      <td>s</td>\n",
       "      <td>a</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2235 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1  2  3    4    5\n",
       "0     f  r  a  k  NaN  NaN\n",
       "1     f  a  s  i    t  NaN\n",
       "2     f  e  c  i    r  NaN\n",
       "3     f  o  n  t  NaN  NaN\n",
       "4     f  l  u  t  NaN  NaN\n",
       "...  .. .. .. ..  ...  ...\n",
       "2230  k  a  l  i    c  NaN\n",
       "2231  k  o  r  v    e    t\n",
       "2232  k  a  s  a    c    i\n",
       "2233  k  o  c  m    a  NaN\n",
       "2234  k  u  m  s    a    l\n",
       "\n",
       "[2235 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tr_split = df_tr['Kelimeler'].apply(lambda x: pd.Series(list(x)))\n",
    "df_tr_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f</td>\n",
       "      <td>l</td>\n",
       "      <td>y</td>\n",
       "      <td>i</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f</td>\n",
       "      <td>i</td>\n",
       "      <td>l</td>\n",
       "      <td>l</td>\n",
       "      <td>e</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f</td>\n",
       "      <td>i</td>\n",
       "      <td>a</td>\n",
       "      <td>n</td>\n",
       "      <td>c</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f</td>\n",
       "      <td>a</td>\n",
       "      <td>i</td>\n",
       "      <td>l</td>\n",
       "      <td>e</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f</td>\n",
       "      <td>a</td>\n",
       "      <td>n</td>\n",
       "      <td>o</td>\n",
       "      <td>n</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21661</th>\n",
       "      <td>k</td>\n",
       "      <td>a</td>\n",
       "      <td>i</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21662</th>\n",
       "      <td>k</td>\n",
       "      <td>v</td>\n",
       "      <td>u</td>\n",
       "      <td>t</td>\n",
       "      <td>z</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21663</th>\n",
       "      <td>k</td>\n",
       "      <td>o</td>\n",
       "      <td>r</td>\n",
       "      <td>e</td>\n",
       "      <td>r</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21664</th>\n",
       "      <td>k</td>\n",
       "      <td>e</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>l</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21665</th>\n",
       "      <td>k</td>\n",
       "      <td>u</td>\n",
       "      <td>r</td>\n",
       "      <td>v</td>\n",
       "      <td>e</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21666 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1  2  3    4    5\n",
       "0      f  l  y  i    n    g\n",
       "1      f  i  l  l    e    t\n",
       "2      f  i  a  n    c    e\n",
       "3      f  a  i  l    e    d\n",
       "4      f  a  n  o    n    s\n",
       "...   .. .. .. ..  ...  ...\n",
       "21661  k  a  i  n  NaN  NaN\n",
       "21662  k  v  u  t    z    a\n",
       "21663  k  o  r  e    r    o\n",
       "21664  k  e  e  n    l    y\n",
       "21665  k  u  r  v    e    y\n",
       "\n",
       "[21666 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eng_split = df_eng['Words'].astype(str).apply(lambda x: pd.Series(list(x)))\n",
    "df_eng_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the language of the word to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng_split['lang'] = 0\n",
    "df_tr_split['lang'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append the dataframes to create 1 dataframe before the creation of features so that they share the same features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_split = df_eng_split.append(df_tr_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create numeric features with the help of dummy variables(one hot encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummy = pd.get_dummies(df_split, columns=[0,1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The provided datasets are unbalanced\n",
    "### The cause of this unbalance is not stated\n",
    "### Depending on the cause of this unbalance, the testing methods for the algorihms should be different\n",
    "### There are 2 scenarios exploring 2 possible causes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. If the real life distribution of languages is 50-50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate the appended dataset into 2 with respect to language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng_dummy = df_dummy[df_dummy['lang']==0]\n",
    "df_tr_dummy = df_dummy[df_dummy['lang']==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since the distribution is 50-50 test data should be balanced\n",
    "### 447 words from each language for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng_dummy = df_eng_dummy.sample(frac=1,random_state=42).reset_index(drop=True)\n",
    "df_tr_dummy = df_tr_dummy.sample(frac=1,random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr_train = df_tr_dummy[:1788]\n",
    "df_tr_test = df_tr_dummy[1788:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng_train = df_eng_dummy[:21219]\n",
    "df_eng_test = df_eng_dummy[21219:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train and test data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_eng_train.append(df_tr_train)\n",
    "del X_train['lang']\n",
    "X_test = df_eng_test.append(df_tr_test)\n",
    "del X_test['lang']\n",
    "y_train = df_eng_train.append(df_tr_train)['lang']\n",
    "y_test = df_eng_test.append(df_tr_test)['lang']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "85a62a13-2b6a-4c6c-a98b-86eb9fc3a64c",
    "_uuid": "d4c4a2527ddf0a31156b6b5dd3e66c025d18036d"
   },
   "source": [
    "## Testing algorithms\n",
    "### The problem can be solved as a binary classification problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5f6fe121-7568-420e-828e-a47da55f3cc6",
    "_uuid": "aa263fa762f1108d5f089d41ae5d9364376c8003"
   },
   "source": [
    "#### Classifiers:\n",
    "\n",
    "* Logistic Regression\n",
    "* Decision Tree\n",
    "* XGBoost - Not in the sklearn library, XGBoost is a very popular classification algorithm that uses NNs. In my previous work, I have observed that for some cases it works much better than sklearn's algorithms.\n",
    "* Linear Discriminant Analysis\n",
    "* Quadratic Discriminant Analysis\n",
    "* Random Forest\n",
    "* K-Nearest Neighbors\n",
    "* Naive Bayes\n",
    "* Multi-Layer Perceptron\n",
    "* AdaBoost\n",
    "\n",
    "#### Scoring:\n",
    "\n",
    "* precision score\n",
    "* recall score\n",
    "* F1 score\n",
    "* support score\n",
    "* accuracy score\n",
    "* AUC/ROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0997f70c-ad11-44f6-b47e-3ea9f08579cf",
    "_uuid": "d3007beb16cf7e189f26dc2d3a757851cb47b8fd"
   },
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "0b8fac1d-8a41-4e12-b682-aaaf64fe3d7a",
    "_uuid": "c1dc14c0a93c8c4200a80d8060b2b2c3d6515f7a"
   },
   "outputs": [],
   "source": [
    "LR = LogisticRegression()\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro' , 'f1_weighted', 'roc_auc']\n",
    "scores = cross_validate(LR, X_train, y_train, scoring=scoring, cv=5)\n",
    "\n",
    "sorted(scores.keys())\n",
    "LR_fit_time = scores['fit_time'].mean()\n",
    "LR_score_time = scores['score_time'].mean()\n",
    "LR_accuracy = scores['test_accuracy'].mean()\n",
    "LR_precision = scores['test_precision_macro'].mean()\n",
    "LR_recall = scores['test_recall_macro'].mean()\n",
    "LR_f1 = scores['test_f1_weighted'].mean()\n",
    "LR_roc = scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "78f1b3f6-7a73-4d0e-a092-1aea7b142797",
    "_uuid": "cc7b04b85956c27cb9baa0c845cc67f3b29c75cb"
   },
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "daf7b0b9-51a9-4580-8cd7-f4c5952bfeff",
    "_uuid": "2cbb9131f56dd4fedcd86a409cbd37ccea069fea"
   },
   "outputs": [],
   "source": [
    "decision_tree = DecisionTreeClassifier()\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro' , 'f1_weighted', 'roc_auc']\n",
    "scores = cross_validate(decision_tree, X_train, y_train, scoring=scoring, cv=5)\n",
    "\n",
    "sorted(scores.keys())\n",
    "dtree_fit_time = scores['fit_time'].mean()\n",
    "dtree_score_time = scores['score_time'].mean()\n",
    "dtree_accuracy = scores['test_accuracy'].mean()\n",
    "dtree_precision = scores['test_precision_macro'].mean()\n",
    "dtree_recall = scores['test_recall_macro'].mean()\n",
    "dtree_f1 = scores['test_f1_weighted'].mean()\n",
    "dtree_roc = scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM = SVC(probability = True)\n",
    "\n",
    "scoring = ['accuracy','precision_macro', 'recall_macro' , 'f1_weighted', 'roc_auc']\n",
    "scores = cross_validate(SVM, X_train, y_train, scoring=scoring, cv=20)\n",
    "\n",
    "sorted(scores.keys())\n",
    "SVM_fit_time = scores['fit_time'].mean()\n",
    "SVM_score_time = scores['score_time'].mean()\n",
    "SVM_accuracy = scores['test_accuracy'].mean()\n",
    "SVM_precision = scores['test_precision_macro'].mean()\n",
    "SVM_recall = scores['test_recall_macro'].mean()\n",
    "SVM_f1 = scores['test_f1_weighted'].mean()\n",
    "SVM_roc = scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7aa3047c-ad22-4f9f-a521-41b591d79ee3",
    "_uuid": "9c089c92e12d458334f57de19b516e4d4d5decde"
   },
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_cell_guid": "8579f8da-aa68-482e-8270-8bbff7c59fab",
    "_uuid": "7e1c5ed0dfe294ba8133c3cd1c7c90cd5a81b7d9"
   },
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(max_depth=5, learning_rate=0.08, objective= 'binary:logistic',n_jobs=-1)\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro' , 'f1_weighted', 'roc_auc']\n",
    "scores = cross_validate(xgb_model, X_train, y_train, scoring=scoring, cv=5)\n",
    "\n",
    "sorted(scores.keys())\n",
    "XG_fit_time = scores['fit_time'].mean()\n",
    "XG_score_time = scores['score_time'].mean()\n",
    "XG_accuracy = scores['test_accuracy'].mean()\n",
    "XG_precision = scores['test_precision_macro'].mean()\n",
    "XG_recall = scores['test_recall_macro'].mean()\n",
    "XG_f1 = scores['test_f1_weighted'].mean()\n",
    "XG_roc = scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4967d1ee-a32d-4da4-ae64-b57ab78eb60e",
    "_uuid": "5633a6713b467c96057d8517b2377d4f89466da6"
   },
   "source": [
    "#### Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "56bd9ff9-5c97-4bc5-a24d-417e104c508e",
    "_uuid": "fd2aa4e337fa75d75e072e08ba76bb24abe13be1"
   },
   "outputs": [],
   "source": [
    "LDA = LinearDiscriminantAnalysis()\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro' , 'f1_weighted', 'roc_auc']\n",
    "scores = cross_validate(LDA, X_train, y_train, scoring=scoring, cv=5)\n",
    "\n",
    "sorted(scores.keys())\n",
    "LDA_fit_time = scores['fit_time'].mean()\n",
    "LDA_score_time = scores['score_time'].mean()\n",
    "LDA_accuracy = scores['test_accuracy'].mean()\n",
    "LDA_precision = scores['test_precision_macro'].mean()\n",
    "LDA_recall = scores['test_recall_macro'].mean()\n",
    "LDA_f1 = scores['test_f1_weighted'].mean()\n",
    "LDA_roc = scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "09b228af-aa16-4366-ba13-fccfc109c213",
    "_uuid": "fa0af845452ff7b59f459ae1a7f638a89d363750"
   },
   "source": [
    "#### Quadratic Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_cell_guid": "d6adf483-24d6-4443-a37a-f4af75e22942",
    "_uuid": "ac5673baf1bfa00e352c3dddafced30b04ec422c"
   },
   "outputs": [],
   "source": [
    "QDA = QuadraticDiscriminantAnalysis()\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro' , 'f1_weighted', 'roc_auc']\n",
    "scores = cross_validate(QDA, X_train, y_train, scoring=scoring, cv=5)\n",
    "\n",
    "sorted(scores.keys())\n",
    "QDA_fit_time = scores['fit_time'].mean()\n",
    "QDA_score_time = scores['score_time'].mean()\n",
    "QDA_accuracy = scores['test_accuracy'].mean()\n",
    "QDA_precision = scores['test_precision_macro'].mean()\n",
    "QDA_recall = scores['test_recall_macro'].mean()\n",
    "QDA_f1 = scores['test_f1_weighted'].mean()\n",
    "QDA_roc = scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f63bcbf8-3ff4-4ee4-99e4-c1bdf2c92e21",
    "_uuid": "6ff907c9efede755b929952687342da03173ed82"
   },
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_cell_guid": "df8cf376-6350-4326-9f77-75561a27458f",
    "_uuid": "7788590ccdf37fadf6dc46ba38311a1f002ff8bd"
   },
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier()\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro' , 'f1_weighted', 'roc_auc']\n",
    "scores = cross_validate(random_forest, X_train, y_train, scoring=scoring, cv=5)\n",
    "\n",
    "sorted(scores.keys())\n",
    "forest_fit_time = scores['fit_time'].mean()\n",
    "forest_score_time = scores['score_time'].mean()\n",
    "forest_accuracy = scores['test_accuracy'].mean()\n",
    "forest_precision = scores['test_precision_macro'].mean()\n",
    "forest_recall = scores['test_recall_macro'].mean()\n",
    "forest_f1 = scores['test_f1_weighted'].mean()\n",
    "forest_roc = scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2baef918-b418-42be-ac9d-a54a34df71f7",
    "_uuid": "b8030b4bcaafd3b1f1f3462eea2e640ef440881d"
   },
   "source": [
    "#### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_cell_guid": "9a0c12b3-b5f1-43d6-b854-3754ebf5d2d2",
    "_uuid": "1ca37a5cc655669a4e95340e16d429f0f097224e"
   },
   "outputs": [],
   "source": [
    "KNN = KNeighborsClassifier()\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro' , 'f1_weighted', 'roc_auc']\n",
    "scores = cross_validate(KNN, X_train, y_train, scoring=scoring, cv=5)\n",
    "\n",
    "sorted(scores.keys())\n",
    "KNN_fit_time = scores['fit_time'].mean()\n",
    "KNN_score_time = scores['score_time'].mean()\n",
    "KNN_accuracy = scores['test_accuracy'].mean()\n",
    "KNN_precision = scores['test_precision_macro'].mean()\n",
    "KNN_recall = scores['test_recall_macro'].mean()\n",
    "KNN_f1 = scores['test_f1_weighted'].mean()\n",
    "KNN_roc = scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a0bbb30b-9f7d-4cfa-8e32-b52f8da9bcd2",
    "_uuid": "587a7c5f4b2e40f6f3f623423a39d3fb6b900d25"
   },
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_cell_guid": "3424a862-f38f-4a3c-94cc-1683a34047d6",
    "_uuid": "9a925d07aaf836368e64d148de2474ce11e89b54"
   },
   "outputs": [],
   "source": [
    "bayes = GaussianNB()\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro' , 'f1_weighted', 'roc_auc']\n",
    "scores = cross_validate(bayes, X_train, y_train, scoring=scoring, cv=5)\n",
    "\n",
    "sorted(scores.keys())\n",
    "bayes_fit_time = scores['fit_time'].mean()\n",
    "bayes_score_time = scores['score_time'].mean()\n",
    "bayes_accuracy = scores['test_accuracy'].mean()\n",
    "bayes_precision = scores['test_precision_macro'].mean()\n",
    "bayes_recall = scores['test_recall_macro'].mean()\n",
    "bayes_f1 = scores['test_f1_weighted'].mean()\n",
    "bayes_roc = scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP = MLPClassifier()\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro' , 'f1_weighted', 'roc_auc']\n",
    "scores = cross_validate(MLP, X_train, y_train, scoring=scoring, cv=5)\n",
    "\n",
    "sorted(scores.keys())\n",
    "MLP_fit_time = scores['fit_time'].mean()\n",
    "MLP_score_time = scores['score_time'].mean()\n",
    "MLP_accuracy = scores['test_accuracy'].mean()\n",
    "MLP_precision = scores['test_precision_macro'].mean()\n",
    "MLP_recall = scores['test_recall_macro'].mean()\n",
    "MLP_f1 = scores['test_f1_weighted'].mean()\n",
    "MLP_roc = scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ada = AdaBoostClassifier()\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro' , 'f1_weighted', 'roc_auc']\n",
    "scores = cross_validate(Ada, X_train, y_train, scoring=scoring, cv=5)\n",
    "\n",
    "sorted(scores.keys())\n",
    "Ada_fit_time = scores['fit_time'].mean()\n",
    "Ada_score_time = scores['score_time'].mean()\n",
    "Ada_accuracy = scores['test_accuracy'].mean()\n",
    "Ada_precision = scores['test_precision_macro'].mean()\n",
    "Ada_recall = scores['test_recall_macro'].mean()\n",
    "Ada_f1 = scores['test_f1_weighted'].mean()\n",
    "Ada_roc = scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5ac1139e-ded3-4a01-9c3b-9d7d551a93df",
    "_uuid": "1f25ad6adf9231855aacad094ec3f5d4c0ea1a8e"
   },
   "source": [
    "### Comparison <a class=\"anchor\" id=\"sum_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_cell_guid": "29f4cdaf-8b10-4079-8811-ab171df36dbd",
    "_uuid": "d522ac0c8d16d1d8f996cd2bb7e2b654c600a0aa",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Fitting time</th>\n",
       "      <th>Scoring time</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "      <th>AUC_ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>233.567928</td>\n",
       "      <td>2.953619</td>\n",
       "      <td>0.933368</td>\n",
       "      <td>0.907694</td>\n",
       "      <td>0.548088</td>\n",
       "      <td>0.911422</td>\n",
       "      <td>0.868292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>3.554085</td>\n",
       "      <td>0.268532</td>\n",
       "      <td>0.931803</td>\n",
       "      <td>0.810018</td>\n",
       "      <td>0.609895</td>\n",
       "      <td>0.915721</td>\n",
       "      <td>0.851397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>8.489035</td>\n",
       "      <td>0.060797</td>\n",
       "      <td>0.928326</td>\n",
       "      <td>0.877371</td>\n",
       "      <td>0.581288</td>\n",
       "      <td>0.901316</td>\n",
       "      <td>0.841395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.787187</td>\n",
       "      <td>0.032039</td>\n",
       "      <td>0.926718</td>\n",
       "      <td>0.783522</td>\n",
       "      <td>0.564369</td>\n",
       "      <td>0.904104</td>\n",
       "      <td>0.835005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>0.824703</td>\n",
       "      <td>59.645280</td>\n",
       "      <td>0.925588</td>\n",
       "      <td>0.814793</td>\n",
       "      <td>0.534315</td>\n",
       "      <td>0.896449</td>\n",
       "      <td>0.690418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ada</td>\n",
       "      <td>1.318253</td>\n",
       "      <td>0.160910</td>\n",
       "      <td>0.925023</td>\n",
       "      <td>0.754702</td>\n",
       "      <td>0.560132</td>\n",
       "      <td>0.902226</td>\n",
       "      <td>0.821558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MLP</td>\n",
       "      <td>51.725407</td>\n",
       "      <td>0.050510</td>\n",
       "      <td>0.923198</td>\n",
       "      <td>0.729672</td>\n",
       "      <td>0.681041</td>\n",
       "      <td>0.918722</td>\n",
       "      <td>0.868794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Linear Discriminant Analysis</td>\n",
       "      <td>0.919291</td>\n",
       "      <td>0.032215</td>\n",
       "      <td>0.919459</td>\n",
       "      <td>0.706886</td>\n",
       "      <td>0.627276</td>\n",
       "      <td>0.910040</td>\n",
       "      <td>0.816762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.454136</td>\n",
       "      <td>0.016586</td>\n",
       "      <td>0.905029</td>\n",
       "      <td>0.659407</td>\n",
       "      <td>0.643267</td>\n",
       "      <td>0.902405</td>\n",
       "      <td>0.644344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bayes</td>\n",
       "      <td>0.047549</td>\n",
       "      <td>0.031118</td>\n",
       "      <td>0.267657</td>\n",
       "      <td>0.544488</td>\n",
       "      <td>0.596059</td>\n",
       "      <td>0.329306</td>\n",
       "      <td>0.610336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Quadratic Discriminant Analysis</td>\n",
       "      <td>0.601331</td>\n",
       "      <td>0.073089</td>\n",
       "      <td>0.220672</td>\n",
       "      <td>0.543507</td>\n",
       "      <td>0.574683</td>\n",
       "      <td>0.260473</td>\n",
       "      <td>0.746771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Model  Fitting time  Scoring time  Accuracy  \\\n",
       "2            Support Vector Machine    233.567928      2.953619  0.933368   \n",
       "6                     Random Forest      3.554085      0.268532  0.931803   \n",
       "3                           XGBoost      8.489035      0.060797  0.928326   \n",
       "0               Logistic Regression      0.787187      0.032039  0.926718   \n",
       "7               K-Nearest Neighbors      0.824703     59.645280  0.925588   \n",
       "10                              Ada      1.318253      0.160910  0.925023   \n",
       "9                               MLP     51.725407      0.050510  0.923198   \n",
       "4      Linear Discriminant Analysis      0.919291      0.032215  0.919459   \n",
       "1                     Decision Tree      0.454136      0.016586  0.905029   \n",
       "8                             Bayes      0.047549      0.031118  0.267657   \n",
       "5   Quadratic Discriminant Analysis      0.601331      0.073089  0.220672   \n",
       "\n",
       "    Precision    Recall  F1_score   AUC_ROC  \n",
       "2    0.907694  0.548088  0.911422  0.868292  \n",
       "6    0.810018  0.609895  0.915721  0.851397  \n",
       "3    0.877371  0.581288  0.901316  0.841395  \n",
       "0    0.783522  0.564369  0.904104  0.835005  \n",
       "7    0.814793  0.534315  0.896449  0.690418  \n",
       "10   0.754702  0.560132  0.902226  0.821558  \n",
       "9    0.729672  0.681041  0.918722  0.868794  \n",
       "4    0.706886  0.627276  0.910040  0.816762  \n",
       "1    0.659407  0.643267  0.902405  0.644344  \n",
       "8    0.544488  0.596059  0.329306  0.610336  \n",
       "5    0.543507  0.574683  0.260473  0.746771  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_initial  = pd.DataFrame({\n",
    "    'Model'       : ['Logistic Regression', 'Decision Tree', 'Support Vector Machine', 'XGBoost', 'Linear Discriminant Analysis', 'Quadratic Discriminant Analysis', 'Random Forest', 'K-Nearest Neighbors', 'Bayes', 'MLP', 'Ada'],\n",
    "    'Fitting time': [LR_fit_time, dtree_fit_time, SVM_fit_time, XG_fit_time, LDA_fit_time, QDA_fit_time, forest_fit_time, KNN_fit_time, bayes_fit_time, MLP_fit_time, Ada_fit_time],\n",
    "    'Scoring time': [LR_score_time, dtree_score_time, SVM_score_time, XG_score_time, LDA_score_time, QDA_score_time, forest_score_time, KNN_score_time, bayes_score_time, MLP_score_time, Ada_score_time],\n",
    "    'Accuracy'    : [LR_accuracy, dtree_accuracy, SVM_accuracy, XG_accuracy, LDA_accuracy, QDA_accuracy, forest_accuracy, KNN_accuracy, bayes_accuracy, MLP_accuracy, Ada_accuracy],\n",
    "    'Precision'   : [LR_precision, dtree_precision, SVM_precision, XG_precision, LDA_precision, QDA_precision, forest_precision, KNN_precision, bayes_precision, MLP_precision, Ada_precision],\n",
    "    'Recall'      : [LR_recall, dtree_recall, XG_recall, SVM_recall, LDA_recall, QDA_recall, forest_recall, KNN_recall, bayes_recall, MLP_recall, Ada_recall],\n",
    "    'F1_score'    : [LR_f1, dtree_f1, SVM_f1, XG_f1, LDA_f1, QDA_f1, forest_f1, KNN_f1, bayes_f1, MLP_f1, Ada_f1],\n",
    "    'AUC_ROC'     : [LR_roc, dtree_roc, SVM_roc, XG_roc, LDA_roc, QDA_roc, forest_roc, KNN_roc, bayes_roc, MLP_roc, Ada_roc],\n",
    "    }, columns = ['Model', 'Fitting time', 'Scoring time', 'Accuracy', 'Precision', 'Recall', 'F1_score', 'AUC_ROC',])\n",
    "\n",
    "models_initial.sort_values(by='Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM has the highest accuracy and precision but its recall is one of the lowest. It is also by far the slowest algorithm to train.\n",
    "### Random Forest has high recall but its precison is low\n",
    "### Depending on the importance of precision and recall either algorithm can be chosen\n",
    "### XGBoost can be a good alternative as it is a midway point between precision and recall\n",
    "### F1 and AUC_ROC scores are very comperable between top performing algorithms. They will not be much use when deciding on which algorithm to choose."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8907674c-fcd5-4d95-8a82-8e4088c27b7e",
    "_uuid": "07c8d5537cfdf250173a9dbf7cd1084eaa7af951"
   },
   "source": [
    "## Voting classifier\n",
    "### Every algorithm has strong and weak parts.\n",
    "### Ensembling has the potential create a stronger model using the strong parts of many algorithms.\n",
    "\n",
    "Documentation: If ‘hard’, uses predicted class labels for majority rule voting. Else if ‘soft’, predicts the class label based on the argmax of the sums of the predicted probabilities, which is recommended for an ensemble of well-calibrated classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_cell_guid": "73ac5a8c-7bf9-4b22-bdcd-2fda0d931388",
    "_uuid": "8656b4b9472ccd9e7524096c87e7f3a30ae1db9e"
   },
   "outputs": [],
   "source": [
    "models = [LogisticRegression(),\n",
    "         DecisionTreeClassifier(),\n",
    "         SVM,\n",
    "         xgb_model,\n",
    "         LinearDiscriminantAnalysis(),\n",
    "         QuadraticDiscriminantAnalysis(),\n",
    "         RandomForestClassifier(),\n",
    "         KNeighborsClassifier(),\n",
    "         GaussianNB(),\n",
    "         MLPClassifier(),\n",
    "         AdaBoostClassifier()]\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro' , 'f1_weighted', 'roc_auc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_cell_guid": "82e978b5-c54b-442f-b438-6f7b4c0e2180",
    "_uuid": "7a26bcd8c4673e46e8da2552716d34d3ba767c73",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    scores = cross_validate(model, X_train, y_train, scoring=scoring, cv=5)\n",
    "    #print(model, scores['fit_time'].mean(), scores['score_time'].mean(), scores['test_accuracy'].mean(),\n",
    "          #scores['test_precision_macro'].mean(), scores['test_recall_macro'].mean(), \n",
    "          #scores['test_f1_weighted'].mean(), scores['test_roc_auc'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "978c40b8-7d61-4dad-a9e2-afa9b8c20a7f",
    "_uuid": "5d815a2d52bfa4634534a3515425025b631b7eb8"
   },
   "source": [
    "### Hard <a class=\"anchor\" id=\"hard\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_cell_guid": "f3bdfafa-1d5c-4835-8adc-69b6d84f9ee1",
    "_uuid": "d53115ea1a94f0538c80791952fb70dbba778b85"
   },
   "outputs": [],
   "source": [
    "models_ens = list(zip(['LR', 'DT', 'SVM', 'XGB', 'LDA', 'QDA', 'RF', 'KNN', 'NB', 'MLP', 'Ada'], models))\n",
    "\n",
    "model_ens = VotingClassifier(estimators = models_ens, voting = 'hard')\n",
    "model_ens.fit(X_train, y_train)\n",
    "pred = model_ens.predict(X_test)\n",
    "#prob = model_ens.predict_proba(X_test)[:,1]\n",
    "\n",
    "acc_hard = accuracy_score(y_test, pred)\n",
    "prec_hard = precision_score(y_test, pred)\n",
    "recall_hard = recall_score(y_test, pred)\n",
    "f1_hard = f1_score(y_test, pred)\n",
    "roc_auc_hard = 'not applicable'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e449abb4-4973-4bea-8ba5-1626cd2b7606",
    "_uuid": "2cbd69df20572b42db19f4b8992a93081d887627"
   },
   "source": [
    "### Soft <a class=\"anchor\" id=\"soft\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_cell_guid": "21ebf713-d2ff-41ef-bc53-7a4327477369",
    "_uuid": "4b1c2d935cdebd36878302d9f91589aae2ffe632"
   },
   "outputs": [],
   "source": [
    "model_ens = VotingClassifier(estimators = models_ens, voting = 'soft')\n",
    "model_ens.fit(X_train, y_train)\n",
    "pred = model_ens.predict(X_test)\n",
    "prob = model_ens.predict_proba(X_test)[:,1]\n",
    "\n",
    "acc_soft = accuracy_score(y_test, pred)\n",
    "prec_soft = precision_score(y_test, pred)\n",
    "recall_soft = recall_score(y_test, pred)\n",
    "f1_soft = f1_score(y_test, pred)\n",
    "roc_auc_soft = roc_auc_score(y_test, prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "711aae3f-5d7a-42f6-a61e-26e5d9ee5344",
    "_uuid": "30db99cbbc594da98764879bccc8db9f87247e77"
   },
   "source": [
    "### Comparison <a class=\"anchor\" id=\"sum_3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_cell_guid": "233150f1-df3f-468e-b5e9-e01f25329678",
    "_uuid": "1586af81b5d80a000c2f474ca6d52686db00407a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "      <th>AUC_ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ensembling_soft</td>\n",
       "      <td>0.643177</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.302013</td>\n",
       "      <td>0.458404</td>\n",
       "      <td>0.855107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensembling_hard</td>\n",
       "      <td>0.604027</td>\n",
       "      <td>0.989474</td>\n",
       "      <td>0.210291</td>\n",
       "      <td>0.346863</td>\n",
       "      <td>not applicable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Model  Accuracy  Precision    Recall  F1_score         AUC_ROC\n",
       "1  Ensembling_soft  0.643177   0.950704  0.302013  0.458404        0.855107\n",
       "0  Ensembling_hard  0.604027   0.989474  0.210291  0.346863  not applicable"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_ensembling = pd.DataFrame({\n",
    "    'Model'       : ['Ensembling_hard', 'Ensembling_soft'],\n",
    "    'Accuracy'    : [acc_hard, acc_soft],\n",
    "    'Precision'   : [prec_hard, prec_soft],\n",
    "    'Recall'      : [recall_hard, recall_soft],\n",
    "    'F1_score'    : [f1_hard, f1_soft],\n",
    "    'AUC_ROC'     : [roc_auc_hard, roc_auc_soft],\n",
    "    }, columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1_score', 'AUC_ROC'])\n",
    "\n",
    "models_ensembling.sort_values(by='Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The accuracy and recall of the ensembles are really low, but they are very precise. If precision is really really important they can be used but for most cases they will not be useful."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8b5821d7-315f-44c5-a714-36fdd104b06c",
    "_uuid": "c2d7e6ef2550eb41ffcd4348fdfab8e80751951d"
   },
   "source": [
    "## 2. If the real life distribution of languages is the same as the provided data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_dummy.copy()\n",
    "del X['lang']\n",
    "y = df_dummy['lang']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The distribution of test data should be the same as the provided datasets. If English is much more common, correctly labeling it is more important.\n",
    "### Stratification helps us create the correct distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "_cell_guid": "64f35366-401c-40c5-8b56-dc0b34c7af7c",
    "_uuid": "517bdcce3508ffe1cd26c7605185420271b6f0a3"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, stratify=y, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fdb23edd-4513-4cc6-9ba9-c01538bb63d1",
    "_uuid": "bf1e913b94b55381ff0a8f72afef4a7c598dd10a"
   },
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "_cell_guid": "284fb22e-08ef-45a8-bb62-36e108700519",
    "_uuid": "e51dfec4d0d64a64cb2ff89d19e268b8a388caae"
   },
   "outputs": [],
   "source": [
    "LR = LogisticRegression()\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro' , 'f1_weighted', 'roc_auc']\n",
    "scores = cross_validate(LR, X_train, y_train, scoring=scoring, cv=5)\n",
    "\n",
    "sorted(scores.keys())\n",
    "LR_fit_time = scores['fit_time'].mean()\n",
    "LR_score_time = scores['score_time'].mean()\n",
    "LR_accuracy = scores['test_accuracy'].mean()\n",
    "LR_precision = scores['test_precision_macro'].mean()\n",
    "LR_recall = scores['test_recall_macro'].mean()\n",
    "LR_f1 = scores['test_f1_weighted'].mean()\n",
    "LR_roc = scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "edbd0a7c-0c5b-4e2b-b7ec-171b70ecb5eb",
    "_uuid": "cc5cc4beda9650f2f7b5477da505d13ca9eadc66"
   },
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "_cell_guid": "da498390-1058-4fc6-b3fb-0a897c956d35",
    "_uuid": "f1da5d0db005160c79fa9e3f9f083f827463189c"
   },
   "outputs": [],
   "source": [
    "decision_tree = DecisionTreeClassifier()\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro' , 'f1_weighted', 'roc_auc']\n",
    "scores = cross_validate(decision_tree, X_train, y_train, scoring=scoring, cv=5)\n",
    "\n",
    "sorted(scores.keys())\n",
    "dtree_fit_time = scores['fit_time'].mean()\n",
    "dtree_score_time = scores['score_time'].mean()\n",
    "dtree_accuracy = scores['test_accuracy'].mean()\n",
    "dtree_precision = scores['test_precision_macro'].mean()\n",
    "dtree_recall = scores['test_recall_macro'].mean()\n",
    "dtree_f1 = scores['test_f1_weighted'].mean()\n",
    "dtree_roc = scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM = SVC(probability = True)\n",
    "\n",
    "scoring = ['accuracy','precision_macro', 'recall_macro' , 'f1_weighted', 'roc_auc']\n",
    "scores = cross_validate(SVM, X_train, y_train, scoring=scoring, cv=20)\n",
    "\n",
    "sorted(scores.keys())\n",
    "SVM_fit_time = scores['fit_time'].mean()\n",
    "SVM_score_time = scores['score_time'].mean()\n",
    "SVM_accuracy = scores['test_accuracy'].mean()\n",
    "SVM_precision = scores['test_precision_macro'].mean()\n",
    "SVM_recall = scores['test_recall_macro'].mean()\n",
    "SVM_f1 = scores['test_f1_weighted'].mean()\n",
    "SVM_roc = scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "78fbf044-39c1-44ec-b1bd-34cbd7444f16",
    "_uuid": "002a9ef2e9c42c93c6fb1de19a2aa7b6a3e4157d"
   },
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "_cell_guid": "0e9b4cf0-f64a-4ee3-bb21-afa0371c5209",
    "_uuid": "6bb49f4246a6bb139b3a59c8364bd1be4d8b76c4"
   },
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(max_depth=5, learning_rate=0.08, objective= 'binary:logistic',n_jobs=-1)\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro' , 'f1_weighted', 'roc_auc']\n",
    "scores = cross_validate(xgb_model, X_train, y_train, scoring=scoring, cv=5)\n",
    "\n",
    "sorted(scores.keys())\n",
    "XG_fit_time = scores['fit_time'].mean()\n",
    "XG_score_time = scores['score_time'].mean()\n",
    "XG_accuracy = scores['test_accuracy'].mean()\n",
    "XG_precision = scores['test_precision_macro'].mean()\n",
    "XG_recall = scores['test_recall_macro'].mean()\n",
    "XG_f1 = scores['test_f1_weighted'].mean()\n",
    "XG_roc = scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4ac108d7-6dc2-47dd-aa45-ffe3628b87e4",
    "_uuid": "deb750bf3ff7048e7927c57a123e4171713aebbc"
   },
   "source": [
    "#### Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "_cell_guid": "b505b43d-ce35-4204-93dd-c27ec6bcc335",
    "_uuid": "81d69c4a438cb21b3d8291c995d68f8d9a96812e"
   },
   "outputs": [],
   "source": [
    "LDA = LinearDiscriminantAnalysis()\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro' , 'f1_weighted', 'roc_auc']\n",
    "scores = cross_validate(LDA, X_train, y_train, scoring=scoring, cv=5)\n",
    "\n",
    "sorted(scores.keys())\n",
    "LDA_fit_time = scores['fit_time'].mean()\n",
    "LDA_score_time = scores['score_time'].mean()\n",
    "LDA_accuracy = scores['test_accuracy'].mean()\n",
    "LDA_precision = scores['test_precision_macro'].mean()\n",
    "LDA_recall = scores['test_recall_macro'].mean()\n",
    "LDA_f1 = scores['test_f1_weighted'].mean()\n",
    "LDA_roc = scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e37189a2-811d-4e40-90a0-c72a8de8e67a",
    "_uuid": "59c0dad1889a49b2b258310b31f0eead844d3bd6"
   },
   "source": [
    "#### Quadratic Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "_cell_guid": "074ef6c8-bee3-441d-9ca3-c455720ddde6",
    "_uuid": "6f623b120213bbc98e33fe97960200100183344c"
   },
   "outputs": [],
   "source": [
    "QDA = QuadraticDiscriminantAnalysis()\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro' , 'f1_weighted', 'roc_auc']\n",
    "scores = cross_validate(QDA, X_train, y_train, scoring=scoring, cv=5)\n",
    "\n",
    "sorted(scores.keys())\n",
    "QDA_fit_time = scores['fit_time'].mean()\n",
    "QDA_score_time = scores['score_time'].mean()\n",
    "QDA_accuracy = scores['test_accuracy'].mean()\n",
    "QDA_precision = scores['test_precision_macro'].mean()\n",
    "QDA_recall = scores['test_recall_macro'].mean()\n",
    "QDA_f1 = scores['test_f1_weighted'].mean()\n",
    "QDA_roc = scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a3262941-56ba-480a-bdfb-57283ce47194",
    "_uuid": "42cdf7c0fc506540343a5727baef1354baf37781"
   },
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "_cell_guid": "adfcb5cd-f064-4b10-bb04-a4d56ed0be39",
    "_uuid": "67651ca1e98827cb20ba82190dbc2d1cb97f2d56"
   },
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier()\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro' , 'f1_weighted', 'roc_auc']\n",
    "scores = cross_validate(random_forest, X_train, y_train, scoring=scoring, cv=5)\n",
    "\n",
    "sorted(scores.keys())\n",
    "forest_fit_time = scores['fit_time'].mean()\n",
    "forest_score_time = scores['score_time'].mean()\n",
    "forest_accuracy = scores['test_accuracy'].mean()\n",
    "forest_precision = scores['test_precision_macro'].mean()\n",
    "forest_recall = scores['test_recall_macro'].mean()\n",
    "forest_f1 = scores['test_f1_weighted'].mean()\n",
    "forest_roc = scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bd778255-e869-480f-b008-af3622021889",
    "_uuid": "9dfdb6379fd0609e23897aa70c7a0cfc3f1aa2ab"
   },
   "source": [
    "#### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "_cell_guid": "7bd33980-caa5-419f-be16-e9b398ef97de",
    "_uuid": "a948604b96d721610d431f8ffafd3ef453e6d011"
   },
   "outputs": [],
   "source": [
    "KNN = KNeighborsClassifier()\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro' , 'f1_weighted', 'roc_auc']\n",
    "scores = cross_validate(KNN, X_train, y_train, scoring=scoring, cv=5)\n",
    "\n",
    "sorted(scores.keys())\n",
    "KNN_fit_time = scores['fit_time'].mean()\n",
    "KNN_score_time = scores['score_time'].mean()\n",
    "KNN_accuracy = scores['test_accuracy'].mean()\n",
    "KNN_precision = scores['test_precision_macro'].mean()\n",
    "KNN_recall = scores['test_recall_macro'].mean()\n",
    "KNN_f1 = scores['test_f1_weighted'].mean()\n",
    "KNN_roc = scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8ede8965-f66e-4477-8741-f16d63b3e1c7",
    "_uuid": "b91b8e29d4af07c4cdf98eeb1167ba99b8c0859d"
   },
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "_cell_guid": "e7da85d3-9b40-4fc9-808f-fd759dc98844",
    "_uuid": "7c0948e7d01f71e6f74d58c020cb39538040a4ee"
   },
   "outputs": [],
   "source": [
    "bayes = GaussianNB()\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro' , 'f1_weighted', 'roc_auc']\n",
    "scores = cross_validate(bayes, X_train, y_train, scoring=scoring, cv=5)\n",
    "\n",
    "sorted(scores.keys())\n",
    "bayes_fit_time = scores['fit_time'].mean()\n",
    "bayes_score_time = scores['score_time'].mean()\n",
    "bayes_accuracy = scores['test_accuracy'].mean()\n",
    "bayes_precision = scores['test_precision_macro'].mean()\n",
    "bayes_recall = scores['test_recall_macro'].mean()\n",
    "bayes_f1 = scores['test_f1_weighted'].mean()\n",
    "bayes_roc = scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP = MLPClassifier()\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro' , 'f1_weighted', 'roc_auc']\n",
    "scores = cross_validate(MLP, X_train, y_train, scoring=scoring, cv=5)\n",
    "\n",
    "sorted(scores.keys())\n",
    "MLP_fit_time = scores['fit_time'].mean()\n",
    "MLP_score_time = scores['score_time'].mean()\n",
    "MLP_accuracy = scores['test_accuracy'].mean()\n",
    "MLP_precision = scores['test_precision_macro'].mean()\n",
    "MLP_recall = scores['test_recall_macro'].mean()\n",
    "MLP_f1 = scores['test_f1_weighted'].mean()\n",
    "MLP_roc = scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ada = AdaBoostClassifier()\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro' , 'f1_weighted', 'roc_auc']\n",
    "scores = cross_validate(Ada, X_train, y_train, scoring=scoring, cv=5)\n",
    "\n",
    "sorted(scores.keys())\n",
    "Ada_fit_time = scores['fit_time'].mean()\n",
    "Ada_score_time = scores['score_time'].mean()\n",
    "Ada_accuracy = scores['test_accuracy'].mean()\n",
    "Ada_precision = scores['test_precision_macro'].mean()\n",
    "Ada_recall = scores['test_recall_macro'].mean()\n",
    "Ada_f1 = scores['test_f1_weighted'].mean()\n",
    "Ada_roc = scores['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9c897ecd-be0c-4857-8e10-c2c4d0c3bf2d",
    "_uuid": "57868dd6325e54bb5da345f654c9057a14a82d18"
   },
   "source": [
    "### Comparison <a class=\"anchor\" id=\"sum_2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "_cell_guid": "7e441e01-4f9e-430a-9a88-cae784786e23",
    "_uuid": "1da4be01e1e3ec43f0eaa87e92468a77576bfe46"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Fitting time</th>\n",
       "      <th>Scoring time</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "      <th>AUC_ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>140.257172</td>\n",
       "      <td>2.060714</td>\n",
       "      <td>0.921730</td>\n",
       "      <td>0.894857</td>\n",
       "      <td>0.559684</td>\n",
       "      <td>0.897866</td>\n",
       "      <td>0.866609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>2.709547</td>\n",
       "      <td>0.200707</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.817677</td>\n",
       "      <td>0.616878</td>\n",
       "      <td>0.901735</td>\n",
       "      <td>0.849454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.682664</td>\n",
       "      <td>0.037814</td>\n",
       "      <td>0.915537</td>\n",
       "      <td>0.802023</td>\n",
       "      <td>0.586587</td>\n",
       "      <td>0.892649</td>\n",
       "      <td>0.829942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>6.610818</td>\n",
       "      <td>0.049063</td>\n",
       "      <td>0.915258</td>\n",
       "      <td>0.863695</td>\n",
       "      <td>0.594313</td>\n",
       "      <td>0.885749</td>\n",
       "      <td>0.843781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>0.513070</td>\n",
       "      <td>32.405215</td>\n",
       "      <td>0.913417</td>\n",
       "      <td>0.778225</td>\n",
       "      <td>0.582481</td>\n",
       "      <td>0.890452</td>\n",
       "      <td>0.754896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MLP</td>\n",
       "      <td>39.706351</td>\n",
       "      <td>0.042994</td>\n",
       "      <td>0.912469</td>\n",
       "      <td>0.741434</td>\n",
       "      <td>0.694335</td>\n",
       "      <td>0.907690</td>\n",
       "      <td>0.864565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ada</td>\n",
       "      <td>1.041920</td>\n",
       "      <td>0.124100</td>\n",
       "      <td>0.911409</td>\n",
       "      <td>0.760260</td>\n",
       "      <td>0.573348</td>\n",
       "      <td>0.887157</td>\n",
       "      <td>0.816656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Linear Discriminant Analysis</td>\n",
       "      <td>0.733972</td>\n",
       "      <td>0.033805</td>\n",
       "      <td>0.908340</td>\n",
       "      <td>0.723882</td>\n",
       "      <td>0.631322</td>\n",
       "      <td>0.896482</td>\n",
       "      <td>0.813442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.352374</td>\n",
       "      <td>0.014924</td>\n",
       "      <td>0.887978</td>\n",
       "      <td>0.664211</td>\n",
       "      <td>0.653262</td>\n",
       "      <td>0.886048</td>\n",
       "      <td>0.653976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bayes</td>\n",
       "      <td>0.037983</td>\n",
       "      <td>0.025934</td>\n",
       "      <td>0.278438</td>\n",
       "      <td>0.551693</td>\n",
       "      <td>0.593176</td>\n",
       "      <td>0.327992</td>\n",
       "      <td>0.605396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Quadratic Discriminant Analysis</td>\n",
       "      <td>0.450789</td>\n",
       "      <td>0.061084</td>\n",
       "      <td>0.270349</td>\n",
       "      <td>0.550779</td>\n",
       "      <td>0.587910</td>\n",
       "      <td>0.315575</td>\n",
       "      <td>0.744128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Model  Fitting time  Scoring time  Accuracy  \\\n",
       "2            Support Vector Machine    140.257172      2.060714  0.921730   \n",
       "6                     Random Forest      2.709547      0.200707  0.920000   \n",
       "0               Logistic Regression      0.682664      0.037814  0.915537   \n",
       "3                           XGBoost      6.610818      0.049063  0.915258   \n",
       "7               K-Nearest Neighbors      0.513070     32.405215  0.913417   \n",
       "9                               MLP     39.706351      0.042994  0.912469   \n",
       "10                              Ada      1.041920      0.124100  0.911409   \n",
       "4      Linear Discriminant Analysis      0.733972      0.033805  0.908340   \n",
       "1                     Decision Tree      0.352374      0.014924  0.887978   \n",
       "8                             Bayes      0.037983      0.025934  0.278438   \n",
       "5   Quadratic Discriminant Analysis      0.450789      0.061084  0.270349   \n",
       "\n",
       "    Precision    Recall  F1_score   AUC_ROC  \n",
       "2    0.894857  0.559684  0.897866  0.866609  \n",
       "6    0.817677  0.616878  0.901735  0.849454  \n",
       "0    0.802023  0.586587  0.892649  0.829942  \n",
       "3    0.863695  0.594313  0.885749  0.843781  \n",
       "7    0.778225  0.582481  0.890452  0.754896  \n",
       "9    0.741434  0.694335  0.907690  0.864565  \n",
       "10   0.760260  0.573348  0.887157  0.816656  \n",
       "4    0.723882  0.631322  0.896482  0.813442  \n",
       "1    0.664211  0.653262  0.886048  0.653976  \n",
       "8    0.551693  0.593176  0.327992  0.605396  \n",
       "5    0.550779  0.587910  0.315575  0.744128  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_initial  = pd.DataFrame({\n",
    "    'Model'       : ['Logistic Regression', 'Decision Tree', 'Support Vector Machine', 'XGBoost', 'Linear Discriminant Analysis', 'Quadratic Discriminant Analysis', 'Random Forest', 'K-Nearest Neighbors', 'Bayes', 'MLP', 'Ada'],\n",
    "    'Fitting time': [LR_fit_time, dtree_fit_time, SVM_fit_time, XG_fit_time, LDA_fit_time, QDA_fit_time, forest_fit_time, KNN_fit_time, bayes_fit_time, MLP_fit_time, Ada_fit_time],\n",
    "    'Scoring time': [LR_score_time, dtree_score_time, SVM_score_time, XG_score_time, LDA_score_time, QDA_score_time, forest_score_time, KNN_score_time, bayes_score_time, MLP_score_time, Ada_score_time],\n",
    "    'Accuracy'    : [LR_accuracy, dtree_accuracy, SVM_accuracy, XG_accuracy, LDA_accuracy, QDA_accuracy, forest_accuracy, KNN_accuracy, bayes_accuracy, MLP_accuracy, Ada_accuracy],\n",
    "    'Precision'   : [LR_precision, dtree_precision, SVM_precision, XG_precision, LDA_precision, QDA_precision, forest_precision, KNN_precision, bayes_precision, MLP_precision, Ada_precision],\n",
    "    'Recall'      : [LR_recall, dtree_recall, XG_recall, SVM_recall, LDA_recall, QDA_recall, forest_recall, KNN_recall, bayes_recall, MLP_recall, Ada_recall],\n",
    "    'F1_score'    : [LR_f1, dtree_f1, SVM_f1, XG_f1, LDA_f1, QDA_f1, forest_f1, KNN_f1, bayes_f1, MLP_f1, Ada_f1],\n",
    "    'AUC_ROC'     : [LR_roc, dtree_roc, SVM_roc, XG_roc, LDA_roc, QDA_roc, forest_roc, KNN_roc, bayes_roc, MLP_roc, Ada_roc],\n",
    "    }, columns = ['Model', 'Fitting time', 'Scoring time', 'Accuracy', 'Precision', 'Recall', 'F1_score', 'AUC_ROC',])\n",
    "\n",
    "models_initial.sort_values(by='Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Very Similar to the first scenario\n",
    "### SVM has the highest accuracy and precision but its recall is the lowest. It is also by far the slowest algorithm to train.\n",
    "### Random Forest has high recall but its precison is low\n",
    "### Depending on the importance of precision and recall either algorithm can be chosen\n",
    "### XGBoost can be a good alternative as it is a midway point between precision and recall\n",
    "### F1 and AUC_ROC scores are very comperable between top performing algorithms. They will not be much use when deciding on which algorithm to choose."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8907674c-fcd5-4d95-8a82-8e4088c27b7e",
    "_uuid": "07c8d5537cfdf250173a9dbf7cd1084eaa7af951"
   },
   "source": [
    "## Voting classifier <a class=\"anchor\" id=\"voting\"></a>\n",
    "\n",
    "\n",
    "Documentation: If ‘hard’, uses predicted class labels for majority rule voting. Else if ‘soft’, predicts the class label based on the argmax of the sums of the predicted probabilities, which is recommended for an ensemble of well-calibrated classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "_cell_guid": "73ac5a8c-7bf9-4b22-bdcd-2fda0d931388",
    "_uuid": "8656b4b9472ccd9e7524096c87e7f3a30ae1db9e"
   },
   "outputs": [],
   "source": [
    "models = [LogisticRegression(),\n",
    "         DecisionTreeClassifier(),\n",
    "         SVM,\n",
    "         xgb_model,\n",
    "         LinearDiscriminantAnalysis(),\n",
    "         QuadraticDiscriminantAnalysis(),\n",
    "         RandomForestClassifier(),\n",
    "         KNeighborsClassifier(),\n",
    "         GaussianNB(),\n",
    "         MLPClassifier(),\n",
    "         AdaBoostClassifier()]\n",
    "\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro' , 'f1_weighted', 'roc_auc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "_cell_guid": "82e978b5-c54b-442f-b438-6f7b4c0e2180",
    "_uuid": "7a26bcd8c4673e46e8da2552716d34d3ba767c73",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    scores = cross_validate(model, X_train, y_train, scoring=scoring, cv=5)\n",
    "    #print(model, scores['fit_time'].mean(), scores['score_time'].mean(), scores['test_accuracy'].mean(),\n",
    "          #scores['test_precision_macro'].mean(), scores['test_recall_macro'].mean(), \n",
    "          #scores['test_f1_weighted'].mean(), scores['test_roc_auc'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "978c40b8-7d61-4dad-a9e2-afa9b8c20a7f",
    "_uuid": "5d815a2d52bfa4634534a3515425025b631b7eb8"
   },
   "source": [
    "### Hard <a class=\"anchor\" id=\"hard\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "_cell_guid": "f3bdfafa-1d5c-4835-8adc-69b6d84f9ee1",
    "_uuid": "d53115ea1a94f0538c80791952fb70dbba778b85"
   },
   "outputs": [],
   "source": [
    "models_ens = list(zip(['LR', 'DT', 'SVM', 'XGB', 'LDA', 'QDA', 'RF', 'KNN', 'NB', 'MLP', 'Ada'], models))\n",
    "\n",
    "model_ens = VotingClassifier(estimators = models_ens, voting = 'hard')\n",
    "model_ens.fit(X_train, y_train)\n",
    "pred = model_ens.predict(X_test)\n",
    "#prob = model_ens.predict_proba(X_test)[:,1]\n",
    "\n",
    "acc_hard = accuracy_score(y_test, pred)\n",
    "prec_hard = precision_score(y_test, pred)\n",
    "recall_hard = recall_score(y_test, pred)\n",
    "f1_hard = f1_score(y_test, pred)\n",
    "roc_auc_hard = 'not applicable'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e449abb4-4973-4bea-8ba5-1626cd2b7606",
    "_uuid": "2cbd69df20572b42db19f4b8992a93081d887627"
   },
   "source": [
    "### Soft <a class=\"anchor\" id=\"soft\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "_cell_guid": "21ebf713-d2ff-41ef-bc53-7a4327477369",
    "_uuid": "4b1c2d935cdebd36878302d9f91589aae2ffe632"
   },
   "outputs": [],
   "source": [
    "model_ens = VotingClassifier(estimators = models_ens, voting = 'soft')\n",
    "model_ens.fit(X_train, y_train)\n",
    "pred = model_ens.predict(X_test)\n",
    "prob = model_ens.predict_proba(X_test)[:,1]\n",
    "\n",
    "acc_soft = accuracy_score(y_test, pred)\n",
    "prec_soft = precision_score(y_test, pred)\n",
    "recall_soft = recall_score(y_test, pred)\n",
    "f1_soft = f1_score(y_test, pred)\n",
    "roc_auc_soft = roc_auc_score(y_test, prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "711aae3f-5d7a-42f6-a61e-26e5d9ee5344",
    "_uuid": "30db99cbbc594da98764879bccc8db9f87247e77"
   },
   "source": [
    "### Comparison <a class=\"anchor\" id=\"sum_3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "_cell_guid": "233150f1-df3f-468e-b5e9-e01f25329678",
    "_uuid": "1586af81b5d80a000c2f474ca6d52686db00407a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_score</th>\n",
       "      <th>AUC_ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ensembling_soft</td>\n",
       "      <td>0.922021</td>\n",
       "      <td>0.648562</td>\n",
       "      <td>0.363148</td>\n",
       "      <td>0.465596</td>\n",
       "      <td>0.868849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensembling_hard</td>\n",
       "      <td>0.921017</td>\n",
       "      <td>0.760479</td>\n",
       "      <td>0.227191</td>\n",
       "      <td>0.349862</td>\n",
       "      <td>not applicable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Model  Accuracy  Precision    Recall  F1_score         AUC_ROC\n",
       "1  Ensembling_soft  0.922021   0.648562  0.363148  0.465596        0.868849\n",
       "0  Ensembling_hard  0.921017   0.760479  0.227191  0.349862  not applicable"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_ensembling = pd.DataFrame({\n",
    "    'Model'       : ['Ensembling_hard', 'Ensembling_soft'],\n",
    "    'Accuracy'    : [acc_hard, acc_soft],\n",
    "    'Precision'   : [prec_hard, prec_soft],\n",
    "    'Recall'      : [recall_hard, recall_soft],\n",
    "    'F1_score'    : [f1_hard, f1_soft],\n",
    "    'AUC_ROC'     : [roc_auc_hard, roc_auc_soft],\n",
    "    }, columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1_score', 'AUC_ROC'])\n",
    "\n",
    "models_ensembling.sort_values(by='Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The ensembles will not be useful in this scenario."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Work:\n",
    "### Creating new feautures with n-gram model can improve the performance of the algorithms. As it can detect syllables and common letter patterns better.\n",
    "### Recurrent Neural Networks are really good with sequence data. With sufficient data RNNs can provide better results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
